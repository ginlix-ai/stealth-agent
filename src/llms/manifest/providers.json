{
  "embedding_models": {
    "openai": [
      {
        "id": "text-embedding-3-small",
        "name": "Text Embedding 3 Small",
        "description": "OpenAI's latest small embedding model with 1536 dimensions",
        "dimensions": 1536,
        "max_tokens": 8191,
        "pricing": {
          "input": 0.02,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "text-embedding-3-large",
        "name": "Text Embedding 3 Large",
        "description": "OpenAI's latest large embedding model with 3072 dimensions for higher accuracy",
        "dimensions": 3072,
        "max_tokens": 8191,
        "pricing": {
          "input": 0.13,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "dashscope": [
      {
        "id": "text-embedding-v4",
        "name": "Text Embedding V4",
        "description": "Alibaba's latest multilingual embedding model (Qwen3-Embedding) with flexible dimensions",
        "dimensions": 1536,
        "max_tokens": 8192,
        "pricing": {
          "input": 0.007,
          "unit": "per_1m_tokens"
        }
      }
    ]
  },
  "models": {
    "openai": [
      {
        "id": "gpt-5-mini",
        "name": "GPT-5 Mini",
        "is_reasoning": true,
        "description": "Smaller, faster GPT-5 variant",
        "alias": ["gpt-5-mini-2025-08-07"],
        "pricing": {
          "input": 0.25,
          "cached_input": 0.025,
          "output": 2.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-5-nano",
        "name": "GPT-5 Nano",
        "is_reasoning": true,
        "description": "Smallest, fastest GPT-5 variant",
        "alias": ["gpt-5-nano-2025-08-07"],
        "pricing": {
          "input": 0.05,
          "cached_input": 0.005,
          "output": 0.40,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-5.1-codex",
        "name": "GPT-5.1 Codex",
        "is_reasoning": true,
        "description": "A version of GPT-5.1 optimized for agentic coding in Codex",
        "pricing": {
          "input": 1.25,
          "cached_input": 0.13,
          "output": 10.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-5.1-codex-mini",
        "name": "GPT-5.1 Codex Mini",
        "is_reasoning": true,
        "description": "Smaller, more cost-effective, less-capable version of GPT-5.1-Codex",
        "pricing": {
          "input": 0.25,
          "cached_input": 0.03,
          "output": 2.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-5.1-2025-11-13",
        "name": "GPT-5.1",
        "is_reasoning": true,
        "description": "The best model for coding and agentic tasks with configurable reasoning effort",
        "alias": ["gpt-5.1"],
        "pricing": {
          "input": 1.25,
          "cached_input": 0.13,
          "output": 10.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-5.2-2025-12-11",
        "name": "GPT-5.2",
        "is_reasoning": true,
        "description": "The best model for coding and agentic tasks with configurable reasoning effort",
        "alias": ["gpt-5.2"],
        "pricing": {
          "input": 1.75,
          "cached_input": 0.175,
          "output": 14.00,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "anthropic": [
        {
          "id": "claude-opus-4-6",
        "name": "Claude 4.6 Opus",
        "is_reasoning": true,
        "description": "Claude 4.6 Opus model",
        "alias": ["claude-opus-4.6"],
        "pricing": {
          "input": 5.00,
          "cached_input": 0.50,
          "cache_5m": 6.25,
          "output": 25.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "claude-sonnet-4-6",
        "name": "Claude 4.6 Sonnet",
        "is_reasoning": true,
        "description": "Claude 4.6 Sonnet model",
        "alias": ["claude-sonnet-4.6"],
        "pricing": {
          "input_tiers": [
            {"max_tokens": 200000, "rate": 3.00, "cached_input": 0.30},
            {"max_tokens": null, "rate": 6.00, "cached_input": 0.60}
          ],
          "output_tiers": [
            {"max_tokens": 200000, "rate": 15.00},
            {"max_tokens": null, "rate": 22.50}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_5m": 3.75,
          "cache_1h": 7.50,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "gemini": [
      {
        "id": "gemini-3.1-flash-image-preview",
        "name": "Gemini 3.1 Flash Image Preview",
        "description": "Designed for speed and efficiency, effective for quick interactive responses and high throughput image generation",
        "pricing": {
          "input": 0.25,
          "output": 1.50,
          "output_image": 60.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gemini-3-flash-preview",
        "name": "Gemini 3 Flash Preview",
        "is_reasoning": true,
        "description": "Google's fast and cost-efficient model with thinking capabilities",
        "pricing": {
          "input": 0.50,
          "cached_input": 0.05,
          "output": 3.00,
          "storage": 1.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gemini-3.1-pro-preview",
        "name": "Gemini 3.1 Pro Preview",
        "is_reasoning": true,
        "description": "Google's latest performance, intelligence, and usability improvements for multimodal understanding, agentic capabilities, and vibe-coding",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 200000, "rate": 2.00, "cached_input": 0.20},
            {"max_tokens": null, "rate": 4.00, "cached_input": 0.40}
          ],
          "output_tiers": [
            {"max_tokens": 200000, "rate": 12.00},
            {"max_tokens": null, "rate": 18.00}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_storage": 4.50,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "lm-studio": [],
    "openrouter": [
      {
        "id": "x-ai/grok-4-fast:free",
        "name": "xAI Grok 4 Fast (Free)",
        "is_reasoning": true,
        "description": "xAI's Grok 4 Fast model with reasoning capabilities (free tier)",
        "pricing": {
          "input": 0,
          "output": 0,
          "unit": "per_1m_tokens"
        },
        "context_window": 2000000
      }
    ],
    "deepseek": [
      {
        "id": "deepseek-reasoner",
        "name": "DeepSeek V3.2",
        "is_reasoning": true,
        "description": "DeepSeek's V3.2 reasoning model with extended thinking capabilities",
        "pricing": {
          "input": 0.28,
          "cached_input": 0.028,
          "output": 0.42,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "vllm": [
      {
        "id": "gpt-oss-120b",
        "name": "GPT-OSS-120B",
        "is_reasoning": true,
        "description": "OpenAI's open-source 120B reasoning model",
        "pricing": {
          "input": 0.25,
          "cached_input": 0.025,
          "output": 2.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-oss-20b",
        "name": "GPT-OSS-20B",
        "is_reasoning": true,
        "description": "OpenAI's open-source 20B reasoning model",
        "pricing": {
          "input": 0.05,
          "cached_input": 0.005,
          "output": 0.40,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "z-ai": [
      {
        "id": "glm-4.7",
        "name": "GLM-4.7",
        "is_reasoning": false,
        "description": "Z.AI's GLM-4.7 model with prompt caching support",
        "pricing": {
          "input": 0.60,
          "cached_input": 0.11,
          "output": 2.20,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "z-ai-cn": [
      {
        "id": "glm-5",
        "name": "GLM-5",
        "is_reasoning": true,
        "description": "Z.AI's latest GLM-5 model with input-dependent tiered pricing",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 32000, "rate": 0.55, "cached_input": 0.14},
            {"max_tokens": null, "rate": 0.83, "cached_input": 0.21}
          ],
          "output_tiers": [
            {"max_tokens": 32000, "rate": 2.48},
            {"max_tokens": null, "rate": 3.03}
          ],
          "output_pricing_mode": "input_dependent",
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "glm-4.7",
        "name": "GLM-4.7",
        "is_reasoning": false,
        "description": "Z.AI's GLM-4.7 model with 2D pricing matrix (varies by input AND output length)",
        "pricing": {
          "pricing_mode": "2d_matrix",
          "discount": 0.8,
          "matrix": [
            {
              "input_max": 32000,
              "output_max": 200,
              "input": 0.29,
              "output": 1.14,
              "cached_input": 0.057
            },
            {
              "input_max": 32000,
              "output_max": null,
              "input": 0.43,
              "output": 2.00,
              "cached_input": 0.086
            },
            {
              "input_max": null,
              "output_max": null,
              "input": 0.57,
              "output": 2.29,
              "cached_input": 0.11
            }
          ],
          "unit": "per_1m_tokens"
        }
      }
    ],
    "minimax": [
      {
        "id": "minimax-m2.5",
        "name": "MiniMax-M2.5",
        "alias": ["MiniMax-M2.5", "minimax-m2.5"],
        "description": "MiniMax's M2.5 model",
        "pricing": {
          "input": 0.30,
          "output": 1.20,
          "cached_input": 0.03,
          "cache_storage": 0.375,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "minimax-m2.5-highspeed",
        "name": "MiniMax-M2.5-Highspeed",
        "alias": ["MiniMax-M2.5-highspeed"],
        "description": "MiniMax's M2.5 Highspeed model with faster inference and higher output pricing",
        "pricing": {
          "input": 0.60,
          "output": 2.40,
          "cached_input": 0.03,
          "cache_storage": 0.375,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "volcengine": [
      {
        "id": "doubao-seed-2.0-pro",
        "name": "Doubao Seed 2.0 Pro",
        "is_reasoning": true,
        "description": "Doubao Seed 2.0 Pro - high-capability model with tiered pricing",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 32000, "rate": 3.2, "cached_input": 0.64},
            {"max_tokens": 128000, "rate": 4.8, "cached_input": 0.64},
            {"max_tokens": 256000, "rate": 9.6, "cached_input": 0.64}
          ],
          "output_tiers": [
            {"max_tokens": 32000, "rate": 16.0},
            {"max_tokens": 128000, "rate": 24.0},
            {"max_tokens": 256000, "rate": 48.0}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_storage": 0.017,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "doubao-seed-2.0-lite",
        "name": "Doubao Seed 2.0 Lite",
        "is_reasoning": true,
        "description": "Doubao Seed 2.0 Lite - balanced performance and cost",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 32000, "rate": 0.6, "cached_input": 0.12},
            {"max_tokens": 128000, "rate": 0.9, "cached_input": 0.12},
            {"max_tokens": 256000, "rate": 1.8, "cached_input": 0.12}
          ],
          "output_tiers": [
            {"max_tokens": 32000, "rate": 3.6},
            {"max_tokens": 128000, "rate": 5.4},
            {"max_tokens": 256000, "rate": 10.8}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_storage": 0.017,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "doubao-seed-2.0-mini",
        "name": "Doubao Seed 2.0 Mini",
        "is_reasoning": true,
        "description": "Doubao Seed 2.0 Mini - lightweight and cost-efficient",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 32000, "rate": 0.2, "cached_input": 0.04},
            {"max_tokens": 128000, "rate": 0.4, "cached_input": 0.04},
            {"max_tokens": 256000, "rate": 0.8, "cached_input": 0.04}
          ],
          "output_tiers": [
            {"max_tokens": 32000, "rate": 2.0},
            {"max_tokens": 128000, "rate": 4.0},
            {"max_tokens": 256000, "rate": 8.0}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_storage": 0.017,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "doubao-seed-2.0-code",
        "name": "Doubao Seed 2.0 Code",
        "is_reasoning": true,
        "description": "Doubao Seed 2.0 Code - optimized for coding tasks",
        "pricing": {
          "input_tiers": [
            {"max_tokens": 32000, "rate": 3.2, "cached_input": 0.64},
            {"max_tokens": 128000, "rate": 4.8, "cached_input": 0.64},
            {"max_tokens": 256000, "rate": 9.6, "cached_input": 0.64}
          ],
          "output_tiers": [
            {"max_tokens": 32000, "rate": 16.0},
            {"max_tokens": 128000, "rate": 24.0},
            {"max_tokens": 256000, "rate": 48.0}
          ],
          "output_pricing_mode": "input_dependent",
          "cache_storage": 0.017,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "dashscope": [
      {
        "id": "qwen3.5-plus",
        "name": "Qwen3.5 Plus",
        "is_reasoning": true,
        "description": "Alibaba's Qwen3.5 Plus model with thinking capabilities and 1M context",
        "context_window": 1000000,
        "max_output": 32768,
        "pricing": {
          "input_tiers": [
            {"max_tokens": 128000, "rate": 0.115},
            {"max_tokens": 256000, "rate": 0.287},
            {"max_tokens": 1000000, "rate": 0.573}
          ],
          "output_tiers": [
            {"max_tokens": 128000, "rate": 0.688},
            {"max_tokens": 256000, "rate": 1.72},
            {"max_tokens": 1000000, "rate": 3.44}
          ],
          "output_pricing_mode": "input_dependent",
          "unit": "per_1m_tokens"
        }
      }
    ],
    "groq": [
      {
        "id": "openai/gpt-oss-20b",
        "name": "GPT-OSS-20B (Groq)",
        "is_reasoning": true,
        "description": "OpenAI's open-source 20B MoE reasoning model hosted on Groq (~1000 tps)",
        "context_window": 131072,
        "max_output": 65536,
        "pricing": {
          "input": 0.075,
          "cached_input": 0.037,
          "output": 0.30,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "openai/gpt-oss-120b",
        "name": "GPT-OSS-120B (Groq)",
        "is_reasoning": true,
        "description": "OpenAI's open-source 120B MoE reasoning model hosted on Groq (~500 tps)",
        "context_window": 131072,
        "max_output": 65536,
        "pricing": {
          "input": 0.15,
          "cached_input": 0.075,
          "output": 0.60,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "moonshot": [
      {
        "id": "kimi-for-coding",
        "name": "Kimi for Coding",
        "is_reasoning": true,
        "description": "Moonshot AI's Kimi model optimized for coding tasks",
        "context_window": 262144,
        "pricing": {
          "input": 0.60,
          "cached_input": 0.10,
          "output": 3.00,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "kimi-k2.5",
        "name": "Kimi K2.5",
        "is_reasoning": true,
        "description": "Moonshot AI's Kimi K2.5 multi-modal model with extended context",
        "context_window": 262144,
        "pricing": {
          "input": 0.60,
          "cached_input": 0.10,
          "output": 3.00,
          "unit": "per_1m_tokens"
        }
      }
    ],
    "cerebras": [
      {
        "id": "zai-glm-4.7",
        "name": "GLM-4.7 (Cerebras)",
        "is_reasoning": true,
        "description": "Z.AI's GLM-4.7 model hosted on Cerebras with ~3000 tps inference speed",
        "context_window": 131072,
        "max_output": 40000,
        "pricing": {
          "input": 0.35,
          "output": 0.75,
          "unit": "per_1m_tokens"
        }
      },
      {
        "id": "gpt-oss-120b",
        "name": "GPT-OSS-120B (Cerebras)",
        "is_reasoning": true,
        "description": "OpenAI's open-source 120B MoE reasoning model hosted on Cerebras (~3000 tps)",
        "context_window": 131072,
        "max_output": 40000,
        "pricing": {
          "input": 0.35,
          "output": 0.75,
          "unit": "per_1m_tokens"
        }
      }
    ]
  },
  "provider_config": {
    "openai": {
      "sdk": "openai",
      "base_url": "https://api.openai.com/v1",
      "env_key": "OPENAI_API_KEY",
      "use_response_api": false,
      "byok_eligible": false,
      "display_name": "OpenAI"
    },
    "anthropic": {
      "sdk": "anthropic",
      "env_key": "ANTHROPIC_API_KEY",
      "byok_eligible": false,
      "display_name": "Anthropic"
    },
    "gemini": {
      "sdk": "gemini",
      "env_key": "GEMINI_API_KEY",
      "byok_eligible": true,
      "display_name": "Gemini"
    },
    "lm-studio": {
      "sdk": "openai",
      "base_url": "http://{HOST_IP}:1234/v1",
      "env_key": "lm-studio",
      "dynamic_models": true,
      "default_parameters": {
        "temperature": 0
      }
    },
    "vllm": {
      "sdk": "openai",
      "base_url": "http://{HOST_IP}:8000/v1",
      "env_key": null,
      "dynamic_models": true,
      "use_response_api": true
    },
    "volcengine": {
      "sdk": "openai",
      "base_url": "https://ark.cn-beijing.volces.com/api/v3",
      "env_key": "VOLCENGINE_API_KEY",
      "use_response_api": true
    },
    "openrouter": {
      "sdk": "deepseek",
      "base_url": "https://openrouter.ai/api/v1",
      "env_key": "OPENROUTER_API_KEY",
      "byok_eligible": false,
      "display_name": "OpenRouter"
    },
    "moonshot": {
      "sdk": "anthropic",
      "base_url": "https://api.kimi.com/coding",
      "env_key": "MOONSHOT_API_KEY",
      "use_response_api": false
    },
    "deepseek": {
      "sdk": "anthropic",
      "base_url": "https://api.deepseek.com/anthropic",
      "env_key": "DEEPSEEK_API_KEY",
      "byok_eligible": false,
      "display_name": "DeepSeek"
    },
    "qwen": {
      "sdk": "openai",
      "base_url": "https://openrouter.ai/api/v1",
      "env_key": "OPENROUTER_API_KEY"
    },
    "alibaba": {
      "sdk": "openai",
      "base_url": "https://openrouter.ai/api/v1",
      "env_key": "OPENROUTER_API_KEY"
    },
    "z-ai": {
      "sdk": "anthropic",
      "base_url": "https://api.z.ai/api/anthropic",
      "env_key": "ZAI_API_KEY"
    },
    "z-ai-cn": {
      "sdk": "anthropic",
      "base_url": "https://open.bigmodel.cn/api/anthropic",
      "env_key": "ZAI_CN_API_KEY"
    },
    "minimax": {
      "sdk": "anthropic",
      "base_url": "https://api.minimax.io/anthropic",
      "env_key": "MINIMAX_API_KEY"
    },
    "doubao-anthropic": {
      "sdk": "anthropic",
      "base_url": "https://ark.cn-beijing.volces.com/api/compatible",
      "env_key": "VOLCENGINE_API_KEY"
    },
    "doubao-coding": {
      "sdk": "anthropic",
      "base_url": "https://ark.cn-beijing.volces.com/api/coding",
      "env_key": "VOLCENGINE_API_KEY"
    },
    "dashscope": {
      "sdk": "openai",
      "base_url": "https://dashscope.aliyuncs.com/api/v2/apps/protocols/compatible-mode/v1",
      "env_key": "DASHSCOPE_API_KEY",
      "use_response_api": true
    },
    "dashscope-coding": {
      "sdk": "anthropic",
      "base_url": "https://coding.dashscope.aliyuncs.com/apps/anthropic",
      "env_key": "DASHSCOPE_API_KEY_CODING"
    },
    "groq": {
      "sdk": "openai",
      "base_url": "https://api.groq.com/openai/v1",
      "env_key": "GROQ_API_KEY",
      "use_response_api": true
    },
    "cerebras": {
      "sdk": "openai",
      "base_url": "https://api.cerebras.ai/v1",
      "env_key": "CEREBRAS_API_KEY",
      "use_response_api": false
    },
    "codex-oauth": {
      "sdk": "codex",
      "base_url": "https://chatgpt.com/backend-api/codex",
      "env_key": null,
      "use_response_api": true,
      "auth_type": "oauth",
      "display_name": "ChatGPT Codex"
    }
  },
  "infrastructure_pricing": {
    "TavilySearchTool": {
      "credits_per_use": 16,
      "search_type": "advanced"
    },
    "TavilySearchImages": {
      "credits_per_use": 16,
      "search_type": "advanced"
    },
    "BochaSearchTool": {
      "credits_per_use": 8,
      "search_type": "ai_search",
      "pricing_note": "0.06 RMB per call"
    }
  },
  "credit_conversion": {
    "usd_to_credits_rate": 1000,
    "description": "Conversion rate from USD to credits (1 USD = 1000 credits)"
  }
}
